{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization  \n",
    "\n",
    "Video expressed only in 0 and 1  \n",
    "The outline of the shape becomes clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#read image as grayscale\n",
    "lenna = cv2.imread('lenna.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#binarization in different threshold type\n",
    "ret, lenna_binary = cv2.threshold(lenna, 150, 255, cv2.THRESH_BINARY)\n",
    "ret, lenna_bi_inv = cv2.threshold(lenna, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, lenna_trunc = cv2.threshold(lenna, 150, 255, cv2.THRESH_TRUNC)\n",
    "ret, lenna_tozero = cv2.threshold(lenna, 150, 255, cv2.THRESH_TOZERO)\n",
    "ret, lenna_toz_inv = cv2.threshold(lenna, 150, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "cv2.imshow('lenna', lenna)\n",
    "#show images\n",
    "cv2.imshow('binary', lenna_binary)\n",
    "cv2.imshow('binary_inv', lenna_bi_inv)\n",
    "cv2.imshow('trunc', lenna_trunc)\n",
    "cv2.imshow('tozero', lenna_tozero)\n",
    "cv2.imshow('tozero_inv', lenna_toz_inv)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adaptive threshold binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "hepburn = cv2.imread('hepburn.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "hepburn_mean = cv2.adaptiveThreshold(hepburn, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 31, 10)\n",
    "cv2.imshow('mean_tozero', hepburn_mean)\n",
    "    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find optimal blocksize with trackbar  \n",
    "밑의 코드들 -> 트랙바 값에 따라 이미지가 변하지 않았다. 왜?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep going\n",
      "keep going\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#trackbar call back function\n",
    "def adaptive_binarization(pos):\n",
    "    global hepburn_mean\n",
    "    block_size = 2*pos +1\n",
    "    hepburn_mean = cv2.adaptiveThreshold(hepburn_mean, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, 10)\n",
    "    print('keep going')\n",
    "    cv2.imshow('mean_tozero', hepburn_mean)\n",
    "    \n",
    "def adaptive_binarization_2(pos):\n",
    "    global hepburn_gaussian\n",
    "    block_size = 2*pos +1\n",
    "    hepburn_gaussian = cv2.adaptiveThreshold(hepburn_gaussian, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, 10)\n",
    "    print('keep going')\n",
    "    cv2.imshow('gaussian_tozero', hepburn_gaussian)\n",
    "\n",
    "hepburn = cv2.imread('hepburn.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "hepburn_mean = np.copy(hepburn)\n",
    "hepburn_gaussian = np.copy(hepburn)\n",
    "\n",
    "cv2.namedWindow('mean_tozero')#create window for trackbar\n",
    "cv2.namedWindow('gaussian_tozero')\n",
    "\n",
    "cv2.createTrackbar('block_size', 'mean_tozero', 1, 15, adaptive_binarization)\n",
    "cv2.createTrackbar('block_size', 'gaussian_tozero', 1, 15, adaptive_binarization_2)\n",
    "\n",
    "    \n",
    "while True:\n",
    "    cv2.imshow('mean_tozero', hepburn_mean)\n",
    "    cv2.imshow('gaussian_tozero', hepburn_gaussian)\n",
    "    \n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#trackbar call back function\n",
    "def nothing(pos):\n",
    "    print('pass')\n",
    "    pass\n",
    "\n",
    "#original images\n",
    "hepburn = cv2.imread('hepburn.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "hepburn_mean = np.copy(hepburn)\n",
    "hepburn_gaussian = np.copy(hepburn)\n",
    "\n",
    "#create windows\n",
    "cv2.namedWindow('mean_tozero')#create window for trackbar\n",
    "cv2.namedWindow('gaussian_tozero')\n",
    "\n",
    "#create trackbars\n",
    "cv2.createTrackbar('block_size', 'mean_tozero', 1, 15, nothing)\n",
    "cv2.createTrackbar('block_size', 'gaussian_tozero', 1, 15, nothing)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('mean_tozero', hepburn_mean)\n",
    "    cv2.imshow('gaussian_tozero', hepburn_gaussian)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "         \n",
    "    hepburn_mean = cv2.adaptiveThreshold(hepburn_mean, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, cv2.getTrackbarPos('block_size', 'mean_tozero') * 2 + 1, 10)\n",
    "    hepburn_gaussian = cv2.adaptiveThreshold(hepburn_gaussian, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, cv2.getTrackbarPos('block_size', 'gaussian_tozero')* 2 + 1, 10)\n",
    "    \n",
    "    cv2.imshow('mean_tozero', hepburn_mean)\n",
    "    cv2.imshow('gaussian_tozero', hepburn_gaussian)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contour  \n",
    "cv2.findContours / drawcontours draw contours at original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   1   -1   -1   -1]\n",
      "  [   2    0   -1   -1]\n",
      "  [   3    1   -1   -1]\n",
      "  ...\n",
      "  [1154 1152   -1    6]\n",
      "  [1155 1153   -1    6]\n",
      "  [  -1 1154   -1    6]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "#original color image and gray image\n",
    "world_map = cv2.imread('worldmap.jpg', cv2.IMREAD_COLOR)\n",
    "world_gray = cv2.cvtColor(world_map, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#binarization with gray image\n",
    "_, img_thresh = cv2.threshold(world_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#find contours\n",
    "contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#draw contours at original color image in green\n",
    "#for c in range(len(contours)):\n",
    "    #draw contour in thickness 1\n",
    " #   cv2.drawContours(world_map, contours, c,(0, 255, 0), 1)\n",
    "\n",
    "#draw contours at original color image in green\n",
    "cv2.drawContours(world_map, contours, -1 ,(0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow('map', world_map)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 2) int32 20000.0\n",
      "[[[300 300]]\n",
      "\n",
      " [[300 400]]\n",
      "\n",
      " [[500 400]]\n",
      "\n",
      " [[500 300]]]\n",
      "(244, 1, 2) int32 19854.0\n",
      "[[[200  70]]\n",
      "\n",
      " [[199  71]]\n",
      "\n",
      " [[188  71]]\n",
      "\n",
      " [[187  72]]\n",
      "\n",
      " [[183  72]]\n",
      "\n",
      " [[182  73]]\n",
      "\n",
      " [[179  73]]\n",
      "\n",
      " [[178  74]]\n",
      "\n",
      " [[176  74]]\n",
      "\n",
      " [[175  75]]\n",
      "\n",
      " [[173  75]]\n",
      "\n",
      " [[172  76]]\n",
      "\n",
      " [[170  76]]\n",
      "\n",
      " [[169  77]]\n",
      "\n",
      " [[168  77]]\n",
      "\n",
      " [[167  78]]\n",
      "\n",
      " [[166  78]]\n",
      "\n",
      " [[165  79]]\n",
      "\n",
      " [[164  79]]\n",
      "\n",
      " [[163  80]]\n",
      "\n",
      " [[162  80]]\n",
      "\n",
      " [[161  81]]\n",
      "\n",
      " [[160  81]]\n",
      "\n",
      " [[159  82]]\n",
      "\n",
      " [[158  82]]\n",
      "\n",
      " [[156  84]]\n",
      "\n",
      " [[155  84]]\n",
      "\n",
      " [[153  86]]\n",
      "\n",
      " [[152  86]]\n",
      "\n",
      " [[147  91]]\n",
      "\n",
      " [[146  91]]\n",
      "\n",
      " [[141  96]]\n",
      "\n",
      " [[141  97]]\n",
      "\n",
      " [[136 102]]\n",
      "\n",
      " [[136 103]]\n",
      "\n",
      " [[134 105]]\n",
      "\n",
      " [[134 106]]\n",
      "\n",
      " [[132 108]]\n",
      "\n",
      " [[132 109]]\n",
      "\n",
      " [[131 110]]\n",
      "\n",
      " [[131 111]]\n",
      "\n",
      " [[130 112]]\n",
      "\n",
      " [[130 113]]\n",
      "\n",
      " [[129 114]]\n",
      "\n",
      " [[129 115]]\n",
      "\n",
      " [[128 116]]\n",
      "\n",
      " [[128 117]]\n",
      "\n",
      " [[127 118]]\n",
      "\n",
      " [[127 119]]\n",
      "\n",
      " [[126 120]]\n",
      "\n",
      " [[126 122]]\n",
      "\n",
      " [[125 123]]\n",
      "\n",
      " [[125 125]]\n",
      "\n",
      " [[124 126]]\n",
      "\n",
      " [[124 128]]\n",
      "\n",
      " [[123 129]]\n",
      "\n",
      " [[123 132]]\n",
      "\n",
      " [[122 133]]\n",
      "\n",
      " [[122 137]]\n",
      "\n",
      " [[121 138]]\n",
      "\n",
      " [[121 149]]\n",
      "\n",
      " [[120 150]]\n",
      "\n",
      " [[121 151]]\n",
      "\n",
      " [[121 162]]\n",
      "\n",
      " [[122 163]]\n",
      "\n",
      " [[122 167]]\n",
      "\n",
      " [[123 168]]\n",
      "\n",
      " [[123 171]]\n",
      "\n",
      " [[124 172]]\n",
      "\n",
      " [[124 174]]\n",
      "\n",
      " [[125 175]]\n",
      "\n",
      " [[125 177]]\n",
      "\n",
      " [[126 178]]\n",
      "\n",
      " [[126 180]]\n",
      "\n",
      " [[127 181]]\n",
      "\n",
      " [[127 182]]\n",
      "\n",
      " [[128 183]]\n",
      "\n",
      " [[128 184]]\n",
      "\n",
      " [[129 185]]\n",
      "\n",
      " [[129 186]]\n",
      "\n",
      " [[130 187]]\n",
      "\n",
      " [[130 188]]\n",
      "\n",
      " [[131 189]]\n",
      "\n",
      " [[131 190]]\n",
      "\n",
      " [[132 191]]\n",
      "\n",
      " [[132 192]]\n",
      "\n",
      " [[134 194]]\n",
      "\n",
      " [[134 195]]\n",
      "\n",
      " [[136 197]]\n",
      "\n",
      " [[136 198]]\n",
      "\n",
      " [[141 203]]\n",
      "\n",
      " [[141 204]]\n",
      "\n",
      " [[146 209]]\n",
      "\n",
      " [[147 209]]\n",
      "\n",
      " [[152 214]]\n",
      "\n",
      " [[153 214]]\n",
      "\n",
      " [[155 216]]\n",
      "\n",
      " [[156 216]]\n",
      "\n",
      " [[158 218]]\n",
      "\n",
      " [[159 218]]\n",
      "\n",
      " [[160 219]]\n",
      "\n",
      " [[161 219]]\n",
      "\n",
      " [[162 220]]\n",
      "\n",
      " [[163 220]]\n",
      "\n",
      " [[164 221]]\n",
      "\n",
      " [[165 221]]\n",
      "\n",
      " [[166 222]]\n",
      "\n",
      " [[167 222]]\n",
      "\n",
      " [[168 223]]\n",
      "\n",
      " [[169 223]]\n",
      "\n",
      " [[170 224]]\n",
      "\n",
      " [[172 224]]\n",
      "\n",
      " [[173 225]]\n",
      "\n",
      " [[175 225]]\n",
      "\n",
      " [[176 226]]\n",
      "\n",
      " [[178 226]]\n",
      "\n",
      " [[179 227]]\n",
      "\n",
      " [[182 227]]\n",
      "\n",
      " [[183 228]]\n",
      "\n",
      " [[187 228]]\n",
      "\n",
      " [[188 229]]\n",
      "\n",
      " [[199 229]]\n",
      "\n",
      " [[200 230]]\n",
      "\n",
      " [[201 229]]\n",
      "\n",
      " [[212 229]]\n",
      "\n",
      " [[213 228]]\n",
      "\n",
      " [[217 228]]\n",
      "\n",
      " [[218 227]]\n",
      "\n",
      " [[221 227]]\n",
      "\n",
      " [[222 226]]\n",
      "\n",
      " [[224 226]]\n",
      "\n",
      " [[225 225]]\n",
      "\n",
      " [[227 225]]\n",
      "\n",
      " [[228 224]]\n",
      "\n",
      " [[230 224]]\n",
      "\n",
      " [[231 223]]\n",
      "\n",
      " [[232 223]]\n",
      "\n",
      " [[233 222]]\n",
      "\n",
      " [[234 222]]\n",
      "\n",
      " [[235 221]]\n",
      "\n",
      " [[236 221]]\n",
      "\n",
      " [[237 220]]\n",
      "\n",
      " [[238 220]]\n",
      "\n",
      " [[239 219]]\n",
      "\n",
      " [[240 219]]\n",
      "\n",
      " [[241 218]]\n",
      "\n",
      " [[242 218]]\n",
      "\n",
      " [[244 216]]\n",
      "\n",
      " [[245 216]]\n",
      "\n",
      " [[247 214]]\n",
      "\n",
      " [[248 214]]\n",
      "\n",
      " [[253 209]]\n",
      "\n",
      " [[254 209]]\n",
      "\n",
      " [[259 204]]\n",
      "\n",
      " [[259 203]]\n",
      "\n",
      " [[264 198]]\n",
      "\n",
      " [[264 197]]\n",
      "\n",
      " [[266 195]]\n",
      "\n",
      " [[266 194]]\n",
      "\n",
      " [[268 192]]\n",
      "\n",
      " [[268 191]]\n",
      "\n",
      " [[269 190]]\n",
      "\n",
      " [[269 189]]\n",
      "\n",
      " [[270 188]]\n",
      "\n",
      " [[270 187]]\n",
      "\n",
      " [[271 186]]\n",
      "\n",
      " [[271 185]]\n",
      "\n",
      " [[272 184]]\n",
      "\n",
      " [[272 183]]\n",
      "\n",
      " [[273 182]]\n",
      "\n",
      " [[273 181]]\n",
      "\n",
      " [[274 180]]\n",
      "\n",
      " [[274 178]]\n",
      "\n",
      " [[275 177]]\n",
      "\n",
      " [[275 175]]\n",
      "\n",
      " [[276 174]]\n",
      "\n",
      " [[276 172]]\n",
      "\n",
      " [[277 171]]\n",
      "\n",
      " [[277 168]]\n",
      "\n",
      " [[278 167]]\n",
      "\n",
      " [[278 163]]\n",
      "\n",
      " [[279 162]]\n",
      "\n",
      " [[279 151]]\n",
      "\n",
      " [[280 150]]\n",
      "\n",
      " [[279 149]]\n",
      "\n",
      " [[279 138]]\n",
      "\n",
      " [[278 137]]\n",
      "\n",
      " [[278 133]]\n",
      "\n",
      " [[277 132]]\n",
      "\n",
      " [[277 129]]\n",
      "\n",
      " [[276 128]]\n",
      "\n",
      " [[276 126]]\n",
      "\n",
      " [[275 125]]\n",
      "\n",
      " [[275 123]]\n",
      "\n",
      " [[274 122]]\n",
      "\n",
      " [[274 120]]\n",
      "\n",
      " [[273 119]]\n",
      "\n",
      " [[273 118]]\n",
      "\n",
      " [[272 117]]\n",
      "\n",
      " [[272 116]]\n",
      "\n",
      " [[271 115]]\n",
      "\n",
      " [[271 114]]\n",
      "\n",
      " [[270 113]]\n",
      "\n",
      " [[270 112]]\n",
      "\n",
      " [[269 111]]\n",
      "\n",
      " [[269 110]]\n",
      "\n",
      " [[268 109]]\n",
      "\n",
      " [[268 108]]\n",
      "\n",
      " [[266 106]]\n",
      "\n",
      " [[266 105]]\n",
      "\n",
      " [[264 103]]\n",
      "\n",
      " [[264 102]]\n",
      "\n",
      " [[259  97]]\n",
      "\n",
      " [[259  96]]\n",
      "\n",
      " [[254  91]]\n",
      "\n",
      " [[253  91]]\n",
      "\n",
      " [[248  86]]\n",
      "\n",
      " [[247  86]]\n",
      "\n",
      " [[245  84]]\n",
      "\n",
      " [[244  84]]\n",
      "\n",
      " [[242  82]]\n",
      "\n",
      " [[241  82]]\n",
      "\n",
      " [[240  81]]\n",
      "\n",
      " [[239  81]]\n",
      "\n",
      " [[238  80]]\n",
      "\n",
      " [[237  80]]\n",
      "\n",
      " [[236  79]]\n",
      "\n",
      " [[235  79]]\n",
      "\n",
      " [[234  78]]\n",
      "\n",
      " [[233  78]]\n",
      "\n",
      " [[232  77]]\n",
      "\n",
      " [[231  77]]\n",
      "\n",
      " [[230  76]]\n",
      "\n",
      " [[228  76]]\n",
      "\n",
      " [[227  75]]\n",
      "\n",
      " [[225  75]]\n",
      "\n",
      " [[224  74]]\n",
      "\n",
      " [[222  74]]\n",
      "\n",
      " [[221  73]]\n",
      "\n",
      " [[218  73]]\n",
      "\n",
      " [[217  72]]\n",
      "\n",
      " [[213  72]]\n",
      "\n",
      " [[212  71]]\n",
      "\n",
      " [[201  71]]]\n",
      "500 400\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((480,640, 3), np.uint8)\n",
    "cv2.circle(img, (200, 150), 80, (255, 255, 0), -1)\n",
    "cv2.circle(img, (500, 150), 50, (255, 0, 0), -1)\n",
    "cv2.rectangle(img, (300,300), (500, 400), (0, 255, 255),-1)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#binarization\n",
    "_, img_thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#simply calculate contour구함\n",
    "contours, _ = cv2.findContours(img_thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    print(c.shape, c.dtype, cv2.contourArea(c)) #cv2.contourArea(c)=contour면적\n",
    "    print(c)\n",
    "#0번째contour의 2번째 점의 x, y좌표\n",
    "print(contours[0][2][0][0], contours[0][2][0][1])\n",
    "colors = [(0, 255, 0),(0, 0, 255)]\n",
    "\n",
    "for c in range(len(contours)):\n",
    "    #선의 두께 3으로 c번째 contour 그림\n",
    "    cv2.drawContours(img, contours, c, colors[c], 3)\n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_gray', img_gray)\n",
    "cv2.imshow('img_thresh', img_thresh)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of contours : 6\n",
      "hierarchy (1, 6, 4)\n",
      "0 [ 1 -1 -1 -1]\n",
      "1 [-1  0  2 -1]\n",
      "2 [-1 -1  3  1]\n",
      "3 [ 4 -1 -1  2]\n",
      "4 [ 5  3 -1  2]\n",
      "5 [-1  4 -1  2]\n",
      "[[[ 1 -1 -1 -1]\n",
      "  [-1  0  2 -1]\n",
      "  [-1 -1  3  1]\n",
      "  [ 4 -1 -1  2]\n",
      "  [ 5  3 -1  2]\n",
      "  [-1  4 -1  2]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((480,640, 3), np.uint8)\n",
    "cv2.rectangle(img, (240,40), (400, 440), (255, 255, 255),-1)\n",
    "cv2.rectangle(img, (440,40), (600, 440), (255, 255, 255),-1)\n",
    "cv2.rectangle(img, ( 80,120), (160, 200), (0, 0, 0),-1)\n",
    "cv2.rectangle(img, ( 80,280), (160, 360), (0, 0, 0),-1)\n",
    "cv2.rectangle(img, (270, 70), (370, 410), (0, 0, 0),-1)\n",
    "cv2.rectangle(img, (300,120), (340, 160), (255, 255, 255),-1)\n",
    "cv2.rectangle(img, (300,220), (340, 260), (255, 255, 255),-1)\n",
    "cv2.rectangle(img, (300,320), (340, 360), (255, 255, 255),-1)\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#binarization이미 되어있는 이미지라서 생략\n",
    "#_, img_thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#simply calculate contour구함\n",
    "contours, hierarchy = cv2.findContours(img_gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print('number of contours :',len(contours))\n",
    "print('hierarchy',hierarchy.shape)\n",
    "for i in range(hierarchy.shape[1]):\n",
    "    print(i, hierarchy[0][i])\n",
    "\n",
    "print(hierarchy)\n",
    "colors = [(0, 0, 255), (0, 255, 0),(255, 0, 0), (0,255, 255), (255, 0, 255), (255, 255, 0), (0, 0, 255), (0, 255, 0), (255, 0, 0)]\n",
    "for i in range(len(contours)):\n",
    "    #선의 두께 3으로 c번째 contour 그림\n",
    "    cv2.drawContours(img, contours, i, colors[i], 3)\n",
    "    #contour첫번째점위치보다약간위좌표에숫자출력\n",
    "    pos = contours[i][0][0][0], contours[i][0][0][1]-7\n",
    "    cv2.putText(img, str(i), pos, cv2.FONT_HERSHEY_SIMPLEX, 1.2, colors[i], 3)\n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find contours and detect figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('figures.jpg', cv2.IMREAD_COLOR)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#binarization \n",
    "_, thresh_img = cv2.threshold(img_gray, 250, 255, cv2.THRESH_BINARY)\n",
    "#find contour\n",
    "contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    #선의 두께 3으로 c번째 contour 그림\n",
    "    cv2.drawContours(img, contours, i, (0,0,0), 3)\n",
    "    #contour첫좌표조금위에순서출력\n",
    "    pos = contours[i][0][0][0], contours[i][0][0][1]+7\n",
    "    cv2.putText(img, str(i), pos, cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,0), 3)\n",
    "\n",
    "cv2.imshow('thres',thresh_img)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('figures.jpg', cv2.IMREAD_COLOR)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#binarization \n",
    "_, thresh_img = cv2.threshold(img_gray, 250, 255, cv2.THRESH_BINARY)\n",
    "#find contour\n",
    "contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#근사화 사용해서 출력해보기\n",
    "for cnt in contours:\n",
    "    epsilon = 0.02*cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "    cv2.drawContours(img, [approx], 0,(0,0,0), 3)\n",
    "\n",
    "cv2.imshow('thres',thresh_img)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.isContourConvex(contour): contour가 convex인지 아닌지 판단하여 True 또는 False를 Return합니다. 여기서 convex란 contour line이 볼록하거나 최소한 평평한 것을 의미합니다.(오목한 부분이 없는 것입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "arc = cv2.imread('arc_length.jpg', cv2.IMREAD_COLOR)\n",
    "arc_gray = cv2.cvtColor(arc, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, thresh_img = cv2.threshold(arc_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(arc, contours, -1 ,(0, 255, 0), 1)\n",
    "print('convex?'cv2.isContourConvex(contours[0]))\n",
    "print('contour length:',len(contours))\n",
    "print('contour ')\n",
    "cv2.imshow('arc', arc)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "도형 읽고 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fruit 이미지에 외곽선 그리기\n",
    "import random \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "src = cv2.imread('fruit.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "_, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU)\n",
    "contours, _ = cv2.findContours(src_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "dst = np.zeros((h, w, 3), np.uint8)\n",
    "\n",
    "#contours에서 추출한 외곽선 좌표 직접 그리기\n",
    "for i in range(len(contours)):\n",
    "    color = (random.randint(0,255), random.randint(0, 255), random.randint(0, 255))\n",
    "    cv2.drawContours(dst, contours, i, color, 1, cv2.LINE_AA)\n",
    "    \n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#카메라 영상에서 움직임이 있는 곳에 박스치기\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#감도 설정(카메라 품질 따라 조정이 필요하다)\n",
    "thresh = 25#달라진 픽셀값 기준치\n",
    "max_diff = 5 #달라진 픽셀 갯수 기준치\n",
    "\n",
    "#카메라 캡션 장치 준비\n",
    "a, b, c = None, None, None\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) #폭설정\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) #높이 설정\n",
    "\n",
    "if cap.isOpened():\n",
    "    ret, a = cap.read() #a frame 읽고\n",
    "    ret, b = cap.read() #b frame 읽고\n",
    "    \n",
    "    while ret:\n",
    "        ret, c = cap.read() #c frame 읽어\n",
    "        draw = c.copy() #출력 영상에 사용할 복제본\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        #영상 grayscale변경\n",
    "        a_gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        b_gray = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
    "        c_gray = cv2.cvtColor(c, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        #a-b, b-c 절댓값차이\n",
    "        diff1 = cv2.absdiff(a_gray, b_gray)\n",
    "        diff2 = cv2.absdiff(a_gray, c_gray)\n",
    "        \n",
    "        #threshold값 미만의 차이는 무시\n",
    "        ret, diff1_t = cv2.threshold(diff1, thresh, 255, cv2.THRESH_BINARY)\n",
    "        ret, diff2_t = cv2.threshold(diff2, thresh, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        #두 차이에 대해 AND연산. 두 영상에서 차이가 모두 발견된 경우를 찾는다\n",
    "        diff = cv2.bitwise_and(diff1_t, diff2_t)\n",
    "        \n",
    "        #opening으로 노이즈 제거\n",
    "        k = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
    "        diff  = cv2.morphologyEx(diff, cv2.MORPH_OPEN, k)\n",
    "        \n",
    "        #차이 발생 픽셀 갯수 판단 후 사각형\n",
    "        diff_cnt = cv2.countNonZero(diff)\n",
    "        if diff_cnt > max_diff :\n",
    "            nzero = np.nonzero(diff)#0아닌 픽셀의 좌표 얻기\n",
    "            cv2.rectangle(draw, (min(nzero[1]), min(nzero[0])), (max(nzero[1]), max(nzero[0])), (0, 255, 0),2)\n",
    "            cv2.putText(draw, 'Motion Detected', (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,255))\n",
    "            \n",
    "        #컬러영상, threshold영상 통합해 출력\n",
    "        stacked = np.hstack((draw, cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)))\n",
    "        cv2.imshow('result', stacked)\n",
    "        \n",
    "        #다음 비교를 위해 영상 순서 정리\n",
    "        a=b\n",
    "        b=c\n",
    "        \n",
    "        if cv2.waitKey(1)==27:\n",
    "            break\n",
    "            \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
