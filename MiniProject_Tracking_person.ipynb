{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상에서 특정인물 tracking하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Video Capture\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#pip install opencv-contrib-python : object tracking API\n",
    "\n",
    "# open video file\n",
    "video_path = './images/hwasa.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "#print(cap.get(cv2.CAP_PROP_FPS))\n",
    "#cap.set(cv2.CAP_PROP_FPS, 1)\n",
    "#print(cap.get(cv2.CAP_PROP_FPS))\n",
    "#cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "#cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "output_size = (200,600) # (width, height), 핸드폰에 꽉찰크기\n",
    "\n",
    "# initialize writing video\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') # 코덱\n",
    "out = cv2.VideoWriter('%s_output.mp4'%(video_path.split('/')[2].split('.')[0]), fourcc, cap.get(cv2.CAP_PROP_FPS), output_size)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "\n",
    "# create tracker\n",
    "# 적당히 정확하면서 적당히 시간 소요되는 tracker 선택\n",
    "# initialize tracker\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "tracker = OPENCV_OBJECT_TRACKERS['csrt']()\n",
    "\n",
    "# read first frame\n",
    "ret, img = cap.read()\n",
    "cv2.namedWindow('Select Window')\n",
    "cv2.imshow('Select Window', img)\n",
    "\n",
    "# setting ROI\n",
    "# space bar 누르면 rect에 ROI가 저장\n",
    "rect = cv2.selectROI('Select Window', img, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow('Select Window')\n",
    "\n",
    "# initialize tracker - make tracker follow ROI(rect)\n",
    "tracker.init(img, rect)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        exit()\n",
    "    \n",
    "    # tracker keep following ROI(rect)\n",
    "    #success, box = tracker.update(img)   \n",
    "    success, box = tracker.update(frame) # box는 rect형태(x, y, w, h)\n",
    "    \n",
    "    x, y, w, h = [int(v) for v in box]\n",
    "    #cv2.rectangle(frame, (x,y,w,h), (255,255,255), 3)\n",
    "\n",
    "    result_top = y\n",
    "    result_bottom = y + output_size[1]\n",
    "    result_left = x\n",
    "    result_right = x + output_size[0]\n",
    "    # 예외처리: box가 영상 벗어날 때\n",
    "    #if result_bottom > cap.get(cv2.CAP_PROP_FRAME_HEIGHT):\n",
    "    #    result_bottom = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    #    result_top = result_bottom - output_size[1]\n",
    "    #if result_right > cap.get(cv2.CAP_PROP_FRAME_WIDTH):\n",
    "    #    result_right = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    #    result_left = result_right - output_size[0]\n",
    "    \n",
    "    result_frame = frame[result_top:result_bottom, result_left:result_right]\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('result', result_frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('s'):\n",
    "        print('Start Video Capture')\n",
    "        out.write(result_frame)\n",
    "\n",
    "    elif key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracker 변경해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracker 종류 바꿔서 해보기\n",
    "# initialize tracker\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "tracker = OPENCV_OBJECT_TRACKERS['csrt']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#pip install opencv-contrib-python : object tracking API\n",
    "\n",
    "# open video file\n",
    "video_path = './images/seventeen.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "#print(cap.get(cv2.CAP_PROP_FPS))\n",
    "#cap.set(cv2.CAP_PROP_FPS, 1)\n",
    "#print(cap.get(cv2.CAP_PROP_FPS))\n",
    "#cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "#cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "output_size = (100,150) # (width, height), 핸드폰에 꽉찰크기\n",
    "\n",
    "# initialize writing video\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') # 코덱\n",
    "out = cv2.VideoWriter('%s_output.mp4'%(video_path.split('/')[2].split('.')[0]), fourcc, cap.get(cv2.CAP_PROP_FPS), output_size)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "\n",
    "# create tracker\n",
    "# 적당히 정확하면서 적당히 시간 소요되는 tracker 선택\n",
    "# initialize tracker\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "tracker = OPENCV_OBJECT_TRACKERS['tld']()\n",
    "    \n",
    "# read first frame\n",
    "ret, img = cap.read()\n",
    "cv2.namedWindow('Select Window')\n",
    "cv2.imshow('Select Window', img)\n",
    "\n",
    "# setting ROI\n",
    "# space bar 누르면 rect에 ROI가 저장\n",
    "rect = cv2.selectROI('Select Window', img, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow('Select Window')\n",
    "\n",
    "# initialize tracker - make tracker follow ROI(rect)\n",
    "tracker.init(img, rect)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        exit()\n",
    "    \n",
    "    # tracker keep following ROI(rect)\n",
    "    #success, box = tracker.update(img)   \n",
    "    success, box = tracker.update(frame) # box는 rect형태(x, y, w, h)\n",
    "    \n",
    "    x, y, w, h = [int(v) for v in box]\n",
    "    #cv2.rectangle(frame, (x,y,w,h), (255,255,255), 3)\n",
    "\n",
    "    result_top = y\n",
    "    result_bottom = y + output_size[1]\n",
    "    result_left = x\n",
    "    result_right = x + output_size[0]\n",
    "    # 예외처리: box가 영상 벗어날 때\n",
    "    #if result_bottom > cap.get(cv2.CAP_PROP_FRAME_HEIGHT):\n",
    "    #    result_bottom = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    #    result_top = result_bottom - output_size[1]\n",
    "    #if result_right > cap.get(cv2.CAP_PROP_FRAME_WIDTH):\n",
    "    #    result_right = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    #    result_left = result_right - output_size[0]\n",
    "    \n",
    "    result_frame = frame[result_top:result_bottom, result_left:result_right]\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('result', result_frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('s'):\n",
    "        print('Start Video Capture')\n",
    "        out.write(result_frame)\n",
    "\n",
    "    elif key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종.  \n",
    "흔들림과 크기 조정, 가림현상 극복 해결했으나 녹화가 안됨 ㅠㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잠깐의 백댄서 의한 가림만 있는 화사 영상\n",
    "import cv2\n",
    "import numpy as np\n",
    "#pip install opencv-contrib-python : object tracking API\n",
    "\n",
    "# open video file\n",
    "video_path = './images/hwasa.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "output_size = (375,667) # (width, height), 핸드폰에 꽉찰크기\n",
    "fit_to = 'height'\n",
    "# initialize writing video\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') # 코덱\n",
    "out = cv2.VideoWriter('%s_output.mp4'%(video_path.split('/')[2].split('.')[0]), fourcc, cap.get(cv2.CAP_PROP_FPS), output_size)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "\n",
    "# create tracker\n",
    "# 적당히 정확하면서 적당히 시간 소요되는 tracker 선택\n",
    "# initialize tracker\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "tracker = OPENCV_OBJECT_TRACKERS['csrt']()\n",
    "\n",
    "# global variables\n",
    "top_bottom_list, left_right_list = [], []\n",
    "count=0\n",
    "\n",
    "#main\n",
    "# read first frame\n",
    "ret, img = cap.read()\n",
    "cv2.namedWindow('Select Window')\n",
    "cv2.imshow('Select Window', img)\n",
    "\n",
    "# setting ROI\n",
    "# space bar 누르면 rect에 ROI가 저장\n",
    "rect = cv2.selectROI('Select Window', img, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow('Select Window')\n",
    "\n",
    "# initialize tracker - make tracker follow ROI(rect)\n",
    "tracker.init(img, rect)\n",
    "\n",
    "while True:\n",
    "    # 읽어들인 frame count\n",
    "    count += 1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        exit()\n",
    "    \n",
    "    # tracker keep following ROI(rect)\n",
    "    # perform the tracking process and pass the result to the roi variable\n",
    "    success, box = tracker.update(frame) # box는 rect형태(x, y, w, h)\n",
    "    \n",
    "    x, y, w, h = [int(v) for v in box]\n",
    "    #cv2.rectangle(frame, (x,y,w,h), (255,255,255), 3)\n",
    "    left = x\n",
    "    top = y\n",
    "    right = left + w\n",
    "    bottom = top + h\n",
    "    \n",
    "    top_bottom_list.append(np.array([top, bottom]))\n",
    "    left_right_list.append(np.array([left, right]))\n",
    "    \n",
    "    # use recent 10 elements for crop(window_size=10)\n",
    "    # 흔들림 최소화하기 위한 작업인 듯 하다\n",
    "    if len(top_bottom_list) > 10:\n",
    "        del top_bottom_list[0]\n",
    "        del left_right_list[0]\n",
    "    \n",
    "    # compute (ROI)moving average\n",
    "    avg_height_range = np.mean(top_bottom_list, axis=0) # [[top평균, bottom평균]]\n",
    "    avg_width_range = np.mean(left_right_list, axis=0).astype(np.int)\n",
    "    avg_center = np.array([np.mean(avg_width_range), np.mean(avg_height_range)]) # (x, y)\n",
    "    \n",
    "    # compute scaled (ROI)width and height\n",
    "    scale = 1.3\n",
    "    avg_height = (avg_height_range[1] - avg_height_range[0]) * scale\n",
    "    avg_width = (avg_width_range[1] - avg_width_range[0]) * scale\n",
    "\n",
    "    # compute new scaled ROI\n",
    "    avg_height_range = np.array([avg_center[1] - avg_height/2, avg_center[1]+avg_height/2])\n",
    "    avg_width_range = np.array([avg_center[0] - avg_width/2, avg_center[0] + avg_width/2])\n",
    "    \n",
    "    # fit to output aspect ratio\n",
    "    # 영상크기 예외처리\n",
    "    if fit_to == 'width':\n",
    "        avg_height_range = np.array([\n",
    "            avg_center[1] - avg_width * output_size[1] / output_size[0] / 2,\n",
    "            avg_center[1] + avg_width * output_size[1] / output_size[0] / 2\n",
    "        ]).astype(np.int).clip(0, 9999)\n",
    "        \n",
    "        avg_width_range = avg_width_range.astype(np.int).clip(0,9999)\n",
    "    elif fit_to == 'height':\n",
    "        avg_width_range = np.array([\n",
    "            avg_center[0] - avg_height * output_size[0] / output_size[1] / 2,\n",
    "            avg_center[0] + avg_height * output_size[0] / output_size[1] / 2\n",
    "        ]).astype(np.int).clip(0, 9999)\n",
    "        \n",
    "        avg_height_range = avg_height_range.astype(np.int).clip(0,9999)\n",
    "    \n",
    "    # crop frame\n",
    "    # rectangle 나타내지 않기 위해 copy\n",
    "    result_frame = frame[avg_height_range[0]:avg_height_range[1], avg_width_range[0]:avg_width_range[1]].copy()\n",
    "    \n",
    "    #result frame resize\n",
    "    result_frame = cv2.resize(result_frame, output_size)\n",
    "    \n",
    "    # visualize\n",
    "    pt1 = (int(left),int(top))\n",
    "    pt2 = (int(right), int(bottom))\n",
    "    cv2.rectangle(img, pt1, pt2, (255, 255, 255), 30)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('result', result_frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('w'):\n",
    "        print('Start Video Capture')\n",
    "        out.write(result_frame)\n",
    "\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "# release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러명인 세븐틴 영상 - 역시 가림현상 극복이 어려움\n",
    "import cv2\n",
    "import numpy as np\n",
    "#pip install opencv-contrib-python : object tracking API\n",
    "\n",
    "# open video file\n",
    "video_path = './images/seventeen.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "output_size = (375,667) # (width, height), 핸드폰에 꽉찰크기\n",
    "fit_to = 'height'\n",
    "# initialize writing video\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') # 코덱\n",
    "out = cv2.VideoWriter('%s_output.mp4'%(video_path.split('/')[2].split('.')[0]), fourcc, cap.get(cv2.CAP_PROP_FPS), output_size)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    exit()\n",
    "\n",
    "# create tracker\n",
    "# 적당히 정확하면서 적당히 시간 소요되는 tracker 선택\n",
    "# initialize tracker\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}\n",
    "\n",
    "tracker = OPENCV_OBJECT_TRACKERS['csrt']()\n",
    "\n",
    "# global variables\n",
    "top_bottom_list, left_right_list = [], []\n",
    "count=0\n",
    "\n",
    "#main\n",
    "# read first frame\n",
    "ret, img = cap.read()\n",
    "cv2.namedWindow('Select Window')\n",
    "cv2.imshow('Select Window', img)\n",
    "\n",
    "# setting ROI\n",
    "# space bar 누르면 rect에 ROI가 저장\n",
    "rect = cv2.selectROI('Select Window', img, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow('Select Window')\n",
    "\n",
    "# initialize tracker - make tracker follow ROI(rect)\n",
    "tracker.init(img, rect)\n",
    "\n",
    "while True:\n",
    "    # 읽어들인 frame count\n",
    "    count += 1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        exit()\n",
    "    \n",
    "    # tracker keep following ROI(rect)\n",
    "    # perform the tracking process and pass the result to the roi variable\n",
    "    success, box = tracker.update(frame) # box는 rect형태(x, y, w, h)\n",
    "    \n",
    "    x, y, w, h = [int(v) for v in box]\n",
    "    #cv2.rectangle(frame, (x,y,w,h), (255,255,255), 3)\n",
    "    left = x\n",
    "    top = y\n",
    "    right = left + w\n",
    "    bottom = top + h\n",
    "    \n",
    "    top_bottom_list.append(np.array([top, bottom]))\n",
    "    left_right_list.append(np.array([left, right]))\n",
    "    \n",
    "    # use recent 10 elements for crop(window_size=10)\n",
    "    # 흔들림 최소화하기 위한 작업인 듯 하다\n",
    "    if len(top_bottom_list) > 10:\n",
    "        del top_bottom_list[0]\n",
    "        del left_right_list[0]\n",
    "    \n",
    "    # compute (ROI)moving average\n",
    "    avg_height_range = np.mean(top_bottom_list, axis=0) # [[top평균, bottom평균]]\n",
    "    avg_width_range = np.mean(left_right_list, axis=0).astype(np.int)\n",
    "    avg_center = np.array([np.mean(avg_width_range), np.mean(avg_height_range)]) # (x, y)\n",
    "    \n",
    "    # compute scaled (ROI)width and height\n",
    "    scale = 1.3\n",
    "    avg_height = (avg_height_range[1] - avg_height_range[0]) * scale\n",
    "    avg_width = (avg_width_range[1] - avg_width_range[0]) * scale\n",
    "\n",
    "    # compute new scaled ROI\n",
    "    avg_height_range = np.array([avg_center[1] - avg_height/2, avg_center[1]+avg_height/2])\n",
    "    avg_width_range = np.array([avg_center[0] - avg_width/2, avg_center[0] + avg_width/2])\n",
    "    \n",
    "    # fit to output aspect ratio\n",
    "    # 영상크기 예외처리\n",
    "    if fit_to == 'width':\n",
    "        avg_height_range = np.array([\n",
    "            avg_center[1] - avg_width * output_size[1] / output_size[0] / 2,\n",
    "            avg_center[1] + avg_width * output_size[1] / output_size[0] / 2\n",
    "        ]).astype(np.int).clip(0, 9999)\n",
    "        \n",
    "        avg_width_range = avg_width_range.astype(np.int).clip(0,9999)\n",
    "    elif fit_to == 'height':\n",
    "        avg_width_range = np.array([\n",
    "            avg_center[0] - avg_height * output_size[0] / output_size[1] / 2,\n",
    "            avg_center[0] + avg_height * output_size[0] / output_size[1] / 2\n",
    "        ]).astype(np.int).clip(0, 9999)\n",
    "        \n",
    "        avg_height_range = avg_height_range.astype(np.int).clip(0,9999)\n",
    "    \n",
    "    # crop frame\n",
    "    # rectangle 나타내지 않기 위해 copy\n",
    "    result_frame = frame[avg_height_range[0]:avg_height_range[1], avg_width_range[0]:avg_width_range[1]].copy()\n",
    "    \n",
    "    #result frame resize\n",
    "    result_frame = cv2.resize(result_frame, output_size)\n",
    "    \n",
    "    # visualize\n",
    "    pt1 = (int(left),int(top))\n",
    "    pt2 = (int(right), int(bottom))\n",
    "    cv2.rectangle(img, pt1, pt2, (255, 255, 255), 30)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('result', result_frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('w'):\n",
    "        print('Start Video Capture')\n",
    "        out.write(result_frame)\n",
    "\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "# release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
